import random
cafe_means = [7, 4, 10] #mean happiness value for each cafeteria
cafe_devs = [3, 10, 6] #standard deviation value for each cafeteria

#Jedidiah Koubiessi
#The exploreOnly() function is to be able to visit each cafeteria
#an equal amount of times and return the total happiness
# by looping through
#each cafeteria and the happiness generated from each.
def exploreOnly():
    total_happiness=[0,0,0]#stores happiness from each cafeteria
    visit=100 #amount of time for a vist to each cafeteria
    for v in range(0, visit):
        for i in range(3): #loop through each of the 3 cafeteria
            #calculate happiness score based on the mean
            # and standard deviation for each cafeteria
            happiness = random.normalvariate(cafe_means[i], cafe_devs[i])
            total_happiness[i] += happiness
    sum_total_happiness = sum(total_happiness)
    return sum_total_happiness

# Name: Shwetha Srinivasan
# exploitFunction() is a function where the user tests each
# cafe first, gets a certain happiness value from each cafe
# based a certain happiness value from each cafe based on the
# mean happiness value and standard deviation, and goes to
# that cafe only for the next 297 days. This function
# calculates the expected happiness value at the end
# of the 300 days and returns that value.
# Net regret is calculated by subtracting expected happiness
# from the optimum happiness.

def exploitOnly():
    best_cafe = ""
    optimum_happiness = 0
    # storing happiness values generated by going to each cafe
    # once in separate variables.
    happiness1 = random.normalvariate(cafe_means[0], cafe_std[0])
    happiness2 = random.normalvariate(cafe_means[1], cafe_std[1])
    happiness3 = random.normalvariate(cafe_means[2], cafe_std[2])
    # Adding the happiness values obtained from each cafe
    # in the first three days
    total_happiness = happiness1 + happiness2 + happiness3
    i = 0
    # finding out which cafe is the best based on first
    # three day values
    if (happiness1 > happiness2 and happiness1 > happiness3):
        best_cafe = "1"
    elif (happiness2 > happiness1 and happiness2 > happiness3):
        best_cafe = "2"
    else: #(happiness3 > happiness1 and happiness3 > happiness2):
        best_cafe = "3"
    while 297 > i:
    #Visiting the same cafe the next 297 days.
    # Also, finding the value of optimum happiness based
    # on which cafe is the best
        if(best_cafe == "1"):
            total_happiness += random.normalvariate(cafe_means[0], cafe_std[0])

        elif(best_cafe == "2"):
            total_happiness += random.normalvariate(cafe_means[1], cafe_std[1])

        elif (best_cafe == "3"):
            total_happiness += random.normalvariate(cafe_means[2], cafe_std[2])

        i += 1
    return total_happiness
# storing value returned from the function in expExploitH

# Tanner Moore
# eGreedy
# path that balances exploration and exploitation with the
# use of random number generation based off an e value
def eGreedy(e=10):
    # creating the manipulated variables
    global cafe_means, cafe_devs, optH
    totalHap = 0
    cafe1 = 0
    cafe2 = 0
    cafe3 = 0

    # starting the 300 days
    for day in range(1,301):

        # setting happiness values
        hap1 = random.normalvariate(cafe_means[0], cafe_devs[0])
        hap2 = random.normalvariate(cafe_means[1], cafe_devs[1])
        hap3 = random.normalvariate(cafe_means[2], cafe_devs[2])

        # testing for first three days
        # cafe# values track the overall happiness of a cafeteria
        # throughout the 300 days and determines the best so far
        if day == 1:
            totalHap += hap1
            cafe1 += hap1
            days1 = 1
            avg1 = cafe1 / days1 # begin tracking average
            continue
        if day == 2:
            totalHap += hap2
            cafe2 += hap2
            days2 = 1
            avg2 = cafe2 / days2
            continue
        if day == 3:
            totalHap += hap3
            cafe3 += hap3
            days3 = 1
            avg3 = cafe3 / days3
            continue

        # creating best so far cafe
        if avg1 > avg2 and avg1 > avg3:
            best_so_far = 1
        elif avg2 > avg1 and avg2 > avg3:
            best_so_far = 2
        else:
            best_so_far = 3

        # deciding choice for the day
        r = random.random()
        if r < e/100:
            choice = random.randint(1,3)
        else:
            choice = best_so_far

        # which cafe are we visiting?
        if choice == 1:
            totalHap += hap1
            cafe1 += hap1
            days1 += 1 # how many days we visited specific cafe
            avg1 = cafe1 / days1
        elif choice == 2:
            totalHap += hap2
            cafe2 += hap2
            days2 += 1
            avg2 = cafe2 / days2
        else:
            totalHap += hap3
            cafe3 += hap3
            days3 += 1
            avg3 = cafe3 / days3
    
    return totalHap


# Nate LaForme
# Group 10
# def simulation

# Simulation
def simulation(t, e=10):
    optH = 300 * max(cafe_means)

    expExploreH = (100 * sum(cafe_means))  # expected happiness
    expExploreR = optH - expExploreH  # regret

    expExploitH = exploitOnly()
    expExploitR = optH - expExploitH

    expEGH = (((100 - e) / 100) * 300) * max(cafe_means)
    for i in range(0, 3):
        expEGH += ((e / 100 * 300) * cafe_means[i]) / 3
    expEGR = optH - expEGH

    sum_explore_happiness = 0
    sum_exploit_happiness = 0
    sum_e_greedy_happiness = 0

    for _ in range(t):
        sum_explore_happiness += exploreOnly()
        sum_exploit_happiness += exploitOnly()

        # Call eGreedy
        e_greedy_value = eGreedy(e)
        if not e_greedy_value:  # Ensure default if None or 0
            e_greedy_value = e
        sum_e_greedy_happiness += e_greedy_value

    # Calculate averages
    avg_explore_happiness = sum_explore_happiness / t
    avg_exploit_happiness = sum_exploit_happiness / t
    avg_e_greedy_happiness = sum_e_greedy_happiness / t

    # Expected values
    expected_happiness_explore = cafe_means[0]
    expected_happiness_exploit = cafe_means[2]
    expected_happiness_e_greedy = (cafe_means[1] + cafe_means[2]) / 2

    # Calculate regrets
    expected_regret_explore = optH - expected_happiness_explore
    expected_regret_exploit = optH - expected_happiness_exploit
    expected_regret_e_greedy = optH - expected_happiness_e_greedy

    simulated_regret_explore = optH - avg_explore_happiness
    simulated_regret_exploit = optH - avg_exploit_happiness
    simulated_regret_e_greedy = optH - avg_e_greedy_happiness

    # Print results
    print(f"Optimum Happiness: {optH:.2f}\n")

    print("Explore Only:")
    print(f"  Expected Happiness: {expected_happiness_explore:.2f}")
    print(f"  Expected Regret: {expected_regret_explore:.2f}")
    print(f"  Simulated Happiness: {avg_explore_happiness:.2f}")
    print(f"  Simulated Regret: {simulated_regret_explore:.2f}\n")

    print("Exploit Only:")
    print(f"  Expected Happiness: {expected_happiness_exploit:.2f}")
    print(f"  Expected Regret: {expected_regret_exploit:.2f}")
    print(f"  Simulated Happiness: {avg_exploit_happiness:.2f}")
    print(f"  Simulated Regret: {simulated_regret_exploit:.2f}\n")

    print("eGreedy:")
    print(f"  Expected Happiness: {expected_happiness_e_greedy:.2f}")
    print(f"  Expected Regret: {expected_regret_e_greedy:.2f}")
    print(f"  Simulated Happiness: {avg_e_greedy_happiness:.2f}")
    print(f"  Simulated Regret: {simulated_regret_e_greedy:.2f}\n")

